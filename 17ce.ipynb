{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "def mkdir(path):\n",
    "    #判斷目錄是否存在\n",
    "    #存在：True\n",
    "    #不存在：False\n",
    "    folder = os.path.exists(path)\n",
    "\n",
    "    #判斷結果\n",
    "    if not folder:\n",
    "        #如果不存在，則建立新目錄\n",
    "        os.makedirs(path)\n",
    "        print(path + \" 建立成功\")\n",
    "\n",
    "    else:\n",
    "        print(path + \" 目錄已存在\")\n",
    "\n",
    "        \n",
    "def SeleniumGetPhoto(URL):\n",
    "    CHROMEDRIVER_PATH = './tools/chromedriver'\n",
    "    options = Options() # 啟動無頭模式\n",
    "#     options.add_argument('--headless')  #規避google bug\n",
    "#     options.add_argument('--ignore-certificate-errors')\n",
    "#     options.add_argument('--disable-gpu')\n",
    "#     options.add_argument('--no-sandbox')\n",
    "    driver = webdriver.Chrome(CHROMEDRIVER_PATH,options=options)\n",
    "    driver.get(\"https://www.17ce.com/\")\n",
    "    time.sleep(3)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(2)\n",
    "    driver.find_element(By.ID, \"nav1\").click()\n",
    "    driver.find_element(By.ID, \"url\").click()\n",
    "    driver.find_element(By.ID, \"url\").send_keys(URL)\n",
    "#     driver.find_element(By.ID, \"su\").click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"su\"]').click()\n",
    "    web = URL.replace(\"https://\",\"\").replace(\"/\",\"\")\n",
    "    \n",
    "    datename = time.strftime(\"%Y-%m-%d\", time.localtime())\n",
    "    mkdir(\"./data/\"+web+\"/photo/\"+datename)\n",
    "    \n",
    "    time.sleep(45)  #要調回45秒\n",
    "    driver.execute_script(\"document.body.style.zoom='0.8'\") \n",
    "    time.sleep(5)  #要調回5秒\n",
    "    driver.execute_script(\"window.scrollTo(0,230)\")\n",
    "    \n",
    "    datefile = time.strftime(\" %Y-%m-%d_%H_%M_%S\", time.localtime())\n",
    "    driver.save_screenshot( \"./data/\"+web+\"/photo/\"+datename+\"/\"+web+datefile+\".png\")\n",
    "    soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "    \n",
    "    driver.close()\n",
    "    print(\"完成：\" + web)\n",
    "    return web , soup\n",
    "\n",
    "def RequestsGetcsv(web,soup):\n",
    "    \n",
    "    line = []\n",
    "    fastestnode = []\n",
    "    fastestsec = []\n",
    "    slowestnode = []\n",
    "    slowestsec = []\n",
    "    average = []\n",
    "\n",
    "    table = soup.find(\"tbody\")\n",
    "\n",
    "    for i in table.find_all(\"tr\")[:6]:\n",
    "        line.append(i.find_all(\"td\")[0].text)\n",
    "        fastestnode.append(i.find_all(\"td\")[1].find(\"font\",class_=\"fl\").text)\n",
    "        fastestsec.append(i.find_all(\"td\")[1].find(\"font\",class_=\"fr\").text)\n",
    "        slowestnode.append(i.find_all(\"td\")[2].find(\"font\",class_=\"fl\").text)\n",
    "        slowestsec.append(i.find_all(\"td\")[2].find(\"font\",class_=\"fr\").text)\n",
    "        average.append(i.find_all(\"td\")[3].find(\"font\",class_=\"fr\").text)\n",
    "\n",
    "    result_dict = {\n",
    "        \"URL\":web,\n",
    "        \"時間\":time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
    "        \"線路\":line,\n",
    "        \"最快節點\":fastestnode,\n",
    "        \"最快節點秒數\":fastestsec,\n",
    "        \"最慢節點\":slowestnode,\n",
    "        \"最慢節點秒數\":slowestsec,\n",
    "        \"平均響應\":average\n",
    "\n",
    "    }\n",
    "\n",
    "    result = pd.DataFrame(result_dict,columns=[\"URL\",\"時間\",\"線路\",\"最快節點\",\"最快節點秒數\",\"最慢節點\",\"最慢節點秒數\",\"平均響應\"])\n",
    "    \n",
    "    filepath = \"./data/\"+web+\"/\"+web+\".csv\"\n",
    "    if os.path.isfile(filepath):\n",
    "        print(\"檔案存在。\")\n",
    "        result.to_csv(\"./data/\"+web+\"/\"+web+\".csv\",encoding=\"utf_8_sig\",mode='a',header=False,index=False)\n",
    "    else:\n",
    "        print(\"檔案不存在。\")\n",
    "        result.to_csv(\"./data/\"+web+\"/\"+web+\".csv\",encoding=\"utf_8_sig\",mode='a',index=False)\n",
    "        \n",
    "    print(\"完成紀錄 \"+web+\".csv\")\n",
    "    print(\"==========================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/hqzb.tv/photo/2020-03-12 目錄已存在\n",
      "完成：hqzb.tv\n",
      "檔案存在。\n",
      "完成紀錄 hqzb.tv.csv\n",
      "==========================\n",
      "./data/kl99.tv/photo/2020-03-12 目錄已存在\n",
      "完成：kl99.tv\n",
      "檔案存在。\n",
      "完成紀錄 kl99.tv.csv\n",
      "==========================\n",
      "./data/ldsports.uk/photo/2020-03-12 目錄已存在\n",
      "完成：ldsports.uk\n",
      "檔案存在。\n",
      "完成紀錄 ldsports.uk.csv\n",
      "==========================\n",
      "./data/ldzb8.tv/photo/2020-03-12 目錄已存在\n",
      "完成：ldzb8.tv\n",
      "檔案存在。\n",
      "完成紀錄 ldzb8.tv.csv\n",
      "==========================\n",
      "./data/meiqiu.tv/photo/2020-03-12 目錄已存在\n",
      "完成：meiqiu.tv\n",
      "檔案存在。\n",
      "完成紀錄 meiqiu.tv.csv\n",
      "==========================\n",
      "./data/pinqiu.tv/photo/2020-03-12 目錄已存在\n",
      "完成：pinqiu.tv\n",
      "檔案存在。\n",
      "完成紀錄 pinqiu.tv.csv\n",
      "==========================\n",
      "./data/shanmao.tv/photo/2020-03-12 目錄已存在\n",
      "完成：shanmao.tv\n",
      "檔案存在。\n",
      "完成紀錄 shanmao.tv.csv\n",
      "==========================\n",
      "./data/smtv.io/photo/2020-03-12 目錄已存在\n",
      "完成：smtv.io\n",
      "檔案存在。\n",
      "完成紀錄 smtv.io.csv\n",
      "==========================\n",
      "./data/smzb.io/photo/2020-03-12 目錄已存在\n",
      "完成：smzb.io\n",
      "檔案存在。\n",
      "完成紀錄 smzb.io.csv\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "web_list = pd.read_csv(\"./URL_dict.csv\")\n",
    "for i in web_list[\"URL\"]:\n",
    "    try:\n",
    "        web,soup = SeleniumGetPhoto(i)\n",
    "    except:\n",
    "        print(\"SeleniumGetPhoto 有問題再跑一次\")\n",
    "        web,soup = SeleniumGetPhoto(i)\n",
    "    \n",
    "    try:\n",
    "        RequestsGetcsv(web,soup)\n",
    "    except:\n",
    "        print(\"RequestsGetcsv 有問題再跑一次\")\n",
    "        RequestsGetcsv(web,soup)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
